{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2541, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>night</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_count</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>text_len</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>Skip to content The Company Careers Press Free...</td>\n",
       "      <td>127</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Speaker 1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:33</td>\n",
       "      <td>I’m here by calling the full session of the 48...</td>\n",
       "      <td>41</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Speaker 2</td>\n",
       "      <td>1</td>\n",
       "      <td>00:59</td>\n",
       "      <td>Every four years, we come together to reaffirm...</td>\n",
       "      <td>17</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Kerry Washington</td>\n",
       "      <td>1</td>\n",
       "      <td>01:07</td>\n",
       "      <td>We fight for a more perfect union because we a...</td>\n",
       "      <td>28</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democratic</td>\n",
       "      <td>4</td>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>1</td>\n",
       "      <td>01:18</td>\n",
       "      <td>We must come together to defeat Donald Trump, ...</td>\n",
       "      <td>22</td>\n",
       "      <td>www_rev_com_blog_transcripts2020-democratic-na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        party  night           speaker  speaker_count   time  \\\n",
       "0  Democratic      4           Unknown              1  00:00   \n",
       "1  Democratic      4         Speaker 1              1  00:33   \n",
       "2  Democratic      4         Speaker 2              1  00:59   \n",
       "3  Democratic      4  Kerry Washington              1  01:07   \n",
       "4  Democratic      4    Bernie Sanders              1  01:18   \n",
       "\n",
       "                                                text text_len  \\\n",
       "0  Skip to content The Company Careers Press Free...      127   \n",
       "1  I’m here by calling the full session of the 48...       41   \n",
       "2  Every four years, we come together to reaffirm...       17   \n",
       "3  We fight for a more perfect union because we a...       28   \n",
       "4  We must come together to defeat Donald Trump, ...       22   \n",
       "\n",
       "                                                file  \n",
       "0  www_rev_com_blog_transcripts2020-democratic-na...  \n",
       "1  www_rev_com_blog_transcripts2020-democratic-na...  \n",
       "2  www_rev_com_blog_transcripts2020-democratic-na...  \n",
       "3  www_rev_com_blog_transcripts2020-democratic-na...  \n",
       "4  www_rev_com_blog_transcripts2020-democratic-na...  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the table name\n",
    "conv = 'conventions'\n",
    "\n",
    "# Fetch all rows from the table\n",
    "query = f\"SELECT * FROM {conv};\"\n",
    "df = pd.read_sql_query(query, conv_conn)\n",
    "print (df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and tokenize text function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "\n",
    "# Function to clean and tokenize the lyrics\n",
    "def clean_and_tokenize(text):\n",
    "    if text is None:\n",
    "        return []\n",
    "    # Remove punctuation\n",
    "    clean_text = ''.join([c for c in text if c not in punctuation])\n",
    "    # Convert tokens to lowercase\n",
    "    clean_text = clean_text.lower()\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(clean_text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    #Join tokens into a single string\n",
    "    string_tokens = ' '.join(tokens)\n",
    "    return string_tokens\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query to retrieve the \"text\" column from the \"convention\" table\n",
    "query = '''\n",
    "    SELECT text, party\n",
    "    FROM conventions\n",
    "'''\n",
    "\n",
    "convention_cur.execute(query)\n",
    "\n",
    "# Fetch all the results\n",
    "results = convention_cur.fetchall()\n",
    "\n",
    "# Populate convention_data with the cleaned and tokenized text and party information\n",
    "convention_data = []\n",
    "for row in results:\n",
    "    text = row[0]\n",
    "    party = row[1]\n",
    "\n",
    "    # Clean and tokenize the text\n",
    "    cleaned_text = clean_and_tokenize(text)\n",
    "\n",
    "    # Append the cleaned and tokenized text and party information as a sublist to convention_data\n",
    "    convention_data.append([cleaned_text, party])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['seems like yesterday first convention husband accepted republican nomination became 45th president united states yet energy enthusiasm lead nation real today four years ago know speak husband entire family say forgotten incredible people willing take chance businessmen never worked politics know elected commanderinchief know carry us humbled incredible support still grateful today',\n",
       "  'Republican'],\n",
       " ['takes trust get things done divided government think joe biden colleagues knew points equally valid',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least word_cutoff times. Here's the code to test that if you want it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2332 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text, fw):\n",
    "    \"\"\"Given some text, this returns a dictionary holding the feature words.\n",
    "    \n",
    "    Args:\n",
    "        text (str): A piece of text in a continuous string. Assumes text has been cleaned and case-folded.\n",
    "        fw (set): The feature words that we're considering. A word in `text` must be in `fw` in order to be returned.\n",
    "                  This prevents us from considering very rarely occurring words.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with the words in `text` that appear in `fw`. Words are only counted once.\n",
    "              If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'}, then this would return\n",
    "              a dictionary of {'quick': True, 'fox': True}.\n",
    "    \"\"\"\n",
    "    ret_dict = {}\n",
    "    \n",
    "    for word in text.split():\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True\n",
    "          \n",
    "    return ret_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald': True,'president': True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(509)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.522\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 radical = True           Republ : Democr =     37.0 : 1.0\n",
      "                   votes = True           Democr : Republ =     24.7 : 1.0\n",
      "               greatness = True           Republ : Democr =     22.0 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     19.6 : 1.0\n",
      "                freedoms = True           Republ : Democr =     16.6 : 1.0\n",
      "                   china = True           Republ : Democr =     15.2 : 1.0\n",
      "                   taxes = True           Republ : Democr =     15.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "               countries = True           Republ : Democr =     14.5 : 1.0\n",
      "                  defund = True           Republ : Democr =     14.5 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.4 : 1.0\n",
      "                    mike = True           Republ : Democr =     12.6 : 1.0\n",
      "                    isis = True           Republ : Democr =     12.3 : 1.0\n",
      "                 freedom = True           Republ : Democr =     12.2 : 1.0\n",
      "                  record = True           Republ : Democr =     12.2 : 1.0\n",
      "               terrorist = True           Republ : Democr =     11.3 : 1.0\n",
      "                   crime = True           Republ : Democr =     10.6 : 1.0\n",
      "                  reform = True           Republ : Democr =     10.6 : 1.0\n",
      "                  heroes = True           Republ : Democr =     10.4 : 1.0\n",
      "                    2018 = True           Republ : Democr =     10.2 : 1.0\n",
      "                 culture = True           Republ : Democr =     10.2 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.2 : 1.0\n",
      "                founding = True           Republ : Democr =     10.2 : 1.0\n",
      "                  lowest = True           Republ : Democr =     10.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "The Naive Bayes classifier shows a relatively low accuracy, approximately 52.2%, implying that it correctly predicts the party affiliation for only about 52.2% of the instances in the test set.\n",
    "\n",
    "The output from the 25 most informative features of the classifier provides valuable insights. It shows that many of these features have higher likelihood ratios for the Republican party compared to the Democratic party. Notably, specific words or topics demonstrate a stronger association with the Republican party in the analyzed text data, including terms like \"radical,\" \"greatness,\" \"destroy,\" \"enforcement,\" and \"freedoms.\" These words indicate their prominence in Republican-oriented language and suggest their significance in capturing the distinctive characteristics of Republican text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "websites\n",
      "candidate_data\n",
      "tweets\n"
     ]
    }
   ],
   "source": [
    "# Execute the query to retrieve table names\n",
    "cong_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "# Fetch all the table names\n",
    "tables = cong_cur.fetchall()\n",
    "\n",
    "# Print the table names\n",
    "for table in tables:\n",
    "    print(table[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mo Brooks',\n",
       "  'Republican',\n",
       "  b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq'),\n",
       " ('Mo Brooks',\n",
       "  'Republican',\n",
       "  b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6'),\n",
       " ('Mo Brooks',\n",
       "  'Republican',\n",
       "  b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA')]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate tweet_data with the cleaned and tokenized text and party information\n",
    "tweet_data = []\n",
    "for row in results:\n",
    "    text = row[2].decode('utf-8') # Decode the byte string using UTF-8\n",
    "    party = row[1]\n",
    "\n",
    "    # Clean and tokenize the text\n",
    "    cleaned_text = clean_and_tokenize(text)\n",
    "\n",
    "    # Append the cleaned and tokenized text and party information as a sublist to convention_data\n",
    "    tweet_data.append([cleaned_text, party])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['brooks joins alabama delegation voting flawed funding bill httptco3cwjiwysnq', 'Republican'], ['brooks senate democrats allowing president give americans ’ jobs illegals securetheborder httpstcomzteax8xs6', 'Republican'], ['nasa square event sat 11am – 4pm stop amp hear incredible work done al05 downtownhsv httptcor9zy8wmepa', 'Republican']]\n"
     ]
    }
   ],
   "source": [
    "print (tweet_data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(509)\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: sent video honor veterans republican womens club katy httpstcoukopee1l7c txlege\n",
      "Actual party is Republican and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: continue visits working families already underway austin san antonio places\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: blueeyes92467 rosie ’ get judgment woman made mistake apologized ’ kill anyone\n",
      "Actual party is Republican and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: billkellytexas according close friend mine god hates patriots\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: proverbs 19 dont neglect mothers teaching learn crown grace clothe honor\n",
      "Actual party is Republican and our classifier says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample:\n",
    "    featuresets = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(featuresets)\n",
    "    # Estimate the actual party using the classifier\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifier says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    featuresets = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(featuresets)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3589, 'Democratic': 679}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4663, 'Democratic': 1071})})"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Write a little about what you see in the results_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:the result shows that the  classifier has  a higher accuracy in predicting tweets labeled as 'Republican'. It correctly classified 3589 out of 4268 'Republican' tweets, and misclassified 679 'Republican' tweets as 'Democratic'. On the other hand, for tweets labeled as 'Democratic', the classifier give a lower accuracy. It correctly classified 1017 out of 5734 as 'Democratic', and misclassified 4663 as 'Republican' . This also aligns with observation earlier when we look at the most important features of the classifier which seems to be more sensitive to certain features associated with the 'Republican' party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
